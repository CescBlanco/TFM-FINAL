#IMPORTACI√ìN LIBRERIAS NECESARIAS
import numpy as np
import pandas as pd
import math
import matplotlib.pyplot as plt
import seaborn as sns
import time

from IPython.display import display
from typing import Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    roc_auc_score, accuracy_score, f1_score, recall_score,
    confusion_matrix, roc_curve, auc
)

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier


# FUNCI√ìN PARA LA CARGA DE ARCHIVOS
def load_dataset(file_path, file_type=None, separator=None, encoding='utf-8', **kwargs):
    """
    Loads a dataset in different formats, with support for custom separators, encoding, and more options.
    """
    # If the file type is not specified, infer from file extension
    if not file_type:
        file_type = file_path.split('.')[-1].lower()

    # Load according to the file type
    if file_type == 'csv':
        return pd.read_csv(file_path, sep=separator or ',', encoding=encoding, **kwargs)
    elif file_type in ['xls', 'xlsx']:
        return pd.read_excel(file_path, **kwargs)
    elif file_type == 'json':
        return pd.read_json(file_path, encoding=encoding, **kwargs)
    else:
        raise ValueError(f"File format '{file_type}' not supported. Use 'csv', 'excel', or 'json'.")


#FUNCION PARA EL EDA B√ÅSICO
def eda_basica(df: pd.DataFrame, nombre_df: str = "DataFrame") -> None:
    """
    Realiza un an√°lisis exploratorio b√°sico sobre un DataFrame:
    - Identifica variables num√©ricas y categ√≥ricas
    - Detecta valores nulos y muestra una visualizaci√≥n si los hay
    - Revisa duplicados (filas y columnas)

    Par√°metros:
        df (pd.DataFrame): El DataFrame a analizar
        nombre_df (str): Nombre para mostrar del DataFrame (opcional)
    """
    print(f"\nüìã An√°lisis EDA b√°sico de: {nombre_df}")

    # 1. Tipos de variables
    print("\nüìå Tipos de Variables:")
    num_vbles = df.select_dtypes(include='number').columns.tolist()
    cat_vbles = df.select_dtypes(exclude='number').columns.tolist()
    print(f"üî¢ Variables Num√©ricas: {num_vbles}")
    print(f"üî† Variables Categ√≥ricas: {cat_vbles}")

    # 2. Valores nulos
    print("\nüï≥Ô∏è Variables con valores nulos:")
    missing = df.isnull().sum()
    missing = missing[missing > 0].sort_values(ascending=False)
    missing_percentage = (missing / len(df)) * 100
    missing_df = pd.DataFrame({
        'Total Missing': missing,
        'Percentage Missing': missing_percentage
    })

    if not missing.empty:
        display(missing_df)
        plt.figure(figsize=(10, 6))
        missing.plot(kind='barh', color='salmon')
        plt.title("Variables con Valores Nulos")
        plt.xlabel("Cantidad de valores nulos")
        plt.gca().invert_yaxis()
        plt.grid(True, axis='x', linestyle='--', alpha=0.7)
        plt.show()
    else:
        print("‚úÖ No hay valores nulos en el dataset.")

    # 3. Filas duplicadas
    print("\nüìé Filas duplicadas:")
    duplicadas = df.duplicated().sum()
    if duplicadas > 0:
        print(f"üî¥ Hay {duplicadas} filas duplicadas.")
        display(df[df.duplicated()])
    else:
        print("‚úÖ No hay filas duplicadas.")

    # 4. Columnas duplicadas
    print("\nüìé Columnas duplicadas:")
    columnas_duplicadas = df.T.duplicated().sum()
    if columnas_duplicadas > 0:
        print(f"üî¥ Hay {columnas_duplicadas} columnas duplicadas.")
    else:
        print("‚úÖ No hay columnas duplicadas.")



#------------------------------------------------FUNCIONES MODELO------------------------------------------------------------
def analizar_target_abandono(df: pd.DataFrame, target_col: str = 'Abandono', figsize: Tuple[int, int] = (10, 5),
                             style: str = 'whitegrid', context: str = 'notebook') -> None:

    """
    Muestra un an√°lisis simple del target (churn), incluyendo conteo, proporciones y un gr√°fico.
    
    Par√°metros:
    - df: DataFrame de entrada.
    - target_col: nombre de la columna objetivo (por defecto: 'Abandono').
    - figsize: tama√±o de la figura (tupla).
    - style: estilo de seaborn (por defecto: 'whitegrid').
    - context: contexto de seaborn (por defecto: 'notebook').
    """
    
    # Estilo visual
    sns.set(style=style, context=context)
    plt.rcParams['figure.figsize'] = figsize
    
    # Conteo y proporciones
    print('üîπ Target counts:')
    print(df[target_col].value_counts(dropna=False))
    
    print('\nüîπ Target proportion:')
    print(df[target_col].value_counts(normalize=True))
    
    # Gr√°fico
    sns.countplot(data=df, x=target_col, palette='pastel')
    plt.title('Distribuci√≥n del Target (Abandono)', fontsize=14)
    plt.xlabel(target_col)
    plt.ylabel('Frecuencia')
    plt.show()

def calcular_correlaciones_abandono(df: pd.DataFrame, target_col: str = 'Abandono', top_n: Optional[int] = None) -> pd.Series:

    """
    Calcula las correlaciones de todas las variables num√©ricas con el target.

    Par√°metros:
    - df: DataFrame de entrada.
    - target_col: columna objetivo (por defecto: 'Abandono').
    - top_n: n√∫mero de variables con mayor correlaci√≥n a mostrar (si se desea limitar).

    Retorna:
    - Series con correlaciones ordenadas descendente (m√°s correladas arriba).
    """
    # Asegurar que el target est√© en formato num√©rico
    df[target_col] = df[target_col].astype(int)

    # Seleccionar columnas num√©ricas (incluye el target)
    df_num = df.select_dtypes(include=['number'])

    # Calcular correlaciones con el target
    correlaciones = df_num.corr()[target_col].sort_values(ascending=False)

    # Mostrar top_n si se desea
    if top_n is not None:
        correlaciones = correlaciones.head(top_n)

    print(f"üîπ Correlaciones con '{target_col}':")
    print(correlaciones)

    return correlaciones

def calcular_correlacion_bool(df: pd.DataFrame, objetivo: str = 'Abandono') -> pd.Series:
    """
    Calcula la correlaci√≥n de variables booleanas con la variable objetivo.
    
    Par√°metros:
        df (pd.DataFrame): DataFrame con las columnas booleanas y la variable objetivo.
        objetivo (str): Nombre de la variable objetivo (por defecto 'abandono').
    
    Retorna:
        pd.Series: Correlaci√≥n de cada variable booleana con la variable objetivo,
                   ordenada de mayor a menor, sin incluir la variable objetivo.
    """
    # Seleccionar columnas booleanas
    bool_cols = df.select_dtypes(include='bool').columns.tolist()

    # Asegurarse de que la variable objetivo est√© incluida
    if objetivo not in bool_cols:
        bool_cols.append(objetivo)
    
    # Convertir a int (0/1)
    df_corr = df[bool_cols].astype(int)

    # Calcular correlaci√≥n y ordenar
    correlation = df_corr.corr()[objetivo].drop(objetivo).sort_values(ascending=False)
    return correlation

# ======================================
# 1. SEPARACI√ìN BALANCEADA DEL 20% FINAL
# ======================================
 

def separacion_df_inferencia_test_final(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:

    """
    Separa un DataFrame en un conjunto de validaci√≥n balanceado (20% del total)
    y un conjunto de entrenamiento (80% restante).

    La validaci√≥n contiene 10% de muestras de cada clase (0 y 1) para mantener balance.

    Par√°metros:
    - df (pd.DataFrame): DataFrame original que debe contener la columna 'Abandono'.

    Retorna:
    - df_validacion (pd.DataFrame): conjunto balanceado para validaci√≥n.
    - df_train (pd.DataFrame): conjunto para entrenamiento.
    """

    # Separar por clase
    df_churn_0 = df[df['Abandono'] == 0]
    df_churn_1 = df[df['Abandono'] == 1]

    # Cantidad del 10% de cada clase
    n_10pct_0 = int(0.10 * len(df))
    n_10pct_1 = int(0.10 * len(df))

    # Sample aleatorio (sin reemplazo)
    valid_0 = df_churn_0.sample(n=n_10pct_0, random_state=42)
    valid_1 = df_churn_1.sample(n=n_10pct_1, random_state=42)

    # Concatenar para tener el 20% de validaci√≥n balanceado
    df_validacion = pd.concat([valid_0, valid_1]).reset_index(drop=True)

    # # Crear conjunto de entrenamiento excluyendo los de validaci√≥n
    df_train = df.drop(df_validacion.index).reset_index(drop=True)

    return df_validacion, df_train

def aplicacion_modelo(X: pd.DataFrame, y: pd.Series) -> Tuple:
    """
    Realiza el entrenamiento, optimizaci√≥n (GridSearchCV), evaluaci√≥n y comparaci√≥n
    de varios modelos cl√°sicos para clasificaci√≥n.

    Par√°metros:
    - X (pd.DataFrame o np.ndarray): variables predictoras.
    - y (pd.Series o np.ndarray): variable objetivo binaria.

    Retorna:
    - best_model: mejor estimador entrenado tras optimizaci√≥n.
    - scaler: objeto StandardScaler utilizado para escalar X.
    """

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # ==============================
    # 3. MODELOS Y PAR√ÅMETROS

    modelos = {
        "Regresi√≥n Log√≠stica": LogisticRegression(max_iter=1000, random_state=42),
        "Random Forest": RandomForestClassifier(random_state=42),
        "Gradient Boosting": GradientBoostingClassifier(random_state=42),
        "SVM": SVC(probability=True, random_state=42),
        "KNN": KNeighborsClassifier()
    }

    param_grids = {
        "Regresi√≥n Log√≠stica": {"C": [0.01, 0.1, 1, 10], "penalty": ["l2"], "solver": ["lbfgs"]},
        "Random Forest": {"n_estimators": [100, 200], "max_depth": [None, 5, 10],
                        "min_samples_split": [2, 5], "min_samples_leaf": [1, 2]},
        "Gradient Boosting": {"n_estimators": [100, 200], "learning_rate": [0.01, 0.05, 0.1],
                            "max_depth": [2, 3, 4], "subsample": [0.8, 1.0]},
        "SVM": {"C": [0.1, 1, 10], "kernel": ["rbf", "poly"], "gamma": ["scale", "auto"]},
        "KNN": {"n_neighbors": [3, 5, 7, 9], "weights": ["uniform", "distance"]}
    }

    # ==============================
    # 4. ENTRENAMIENTO Y EVALUACI√ìN

    resultados = []

    plt.figure(figsize=(10, 8))

    for nombre, modelo in modelos.items():
        print(f"\nüîç Optimizando {nombre}...")
        start = time.time()

        grid = GridSearchCV(
            estimator=modelo,
            param_grid=param_grids[nombre],
            scoring='roc_auc',
            cv=5,
            n_jobs=-1,
            verbose=0
        )
        grid.fit(X_train_scaled, y_train)
        tiempo = round(time.time() - start, 2)

        best_model = grid.best_estimator_
        y_pred = best_model.predict(X_test_scaled)
        y_prob = best_model.predict_proba(X_test_scaled)[:, 1] if hasattr(best_model, "predict_proba") else None

        # M√©tricas
        cm = confusion_matrix(y_test, y_pred)

        if y_prob is not None:
            fpr, tpr, thresholds = roc_curve(y_test, y_prob)
            roc_auc = auc(fpr, tpr)
            plt.plot(fpr, tpr, label=f'{nombre} (AUC = {roc_auc:.2f})')
        else:
            roc_auc = None

        resultados.append({
            "Modelo": nombre,
            "Mejores Par√°metros": grid.best_params_,
            "AUC": roc_auc,
            "Accuracy": accuracy_score(y_test, y_pred),
            "Recall": recall_score(y_test, y_pred),
            "F1": f1_score(y_test, y_pred),
            "Matriz Confusi√≥n": cm,
            "Tiempo (s)": tiempo,
            "Best_Model": best_model
        })

    # ==============================
    # 5. RESULTADOS EN DATAFRAME

    df_resultados = pd.DataFrame(resultados).sort_values(by="AUC", ascending=False)
    display(df_resultados)

    # ==============================
    # 6. CURVA ROC COMPARATIVA

    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("Curva ROC de modelos")
    plt.legend(loc="lower right")
    plt.show()

    # ==============================
    # 7. MEJOR MODELO

    mejor_modelo = df_resultados.iloc[0]
    best_model = mejor_modelo["Best_Model"]

    print("\nüèÜ Mejor modelo:")
    print("Modelo:", mejor_modelo["Modelo"])
    print("AUC:", round(mejor_modelo["AUC"], 3))
    print("Accuracy:", round(mejor_modelo["Accuracy"], 3))
    print("Recall:", round(mejor_modelo["Recall"], 3))
    print("F1:", round(mejor_modelo["F1"], 3))
    print("Mejores Par√°metros:", mejor_modelo["Mejores Par√°metros"])
    print("Matriz de Confusi√≥n:\n", mejor_modelo["Matriz Confusi√≥n"])

    # ==============================
    # 8. IMPORTANCIA DE VARIABLES (si aplica)

    if hasattr(best_model, "feature_importances_"):
        importances = pd.DataFrame({
            'Variable': X_train.columns,
            'Importancia': best_model.feature_importances_
        }).sort_values(by='Importancia', ascending=False)

        print("\nüî• Importancia de variables del mejor modelo:")
        display(importances)

        plt.figure(figsize=(10, 6))
        plt.barh(importances['Variable'], importances['Importancia'])
        plt.gca().invert_yaxis()
        plt.title(f"Top variables - {mejor_modelo['Modelo']}")
        plt.show()
    else:
        print("\n‚ö†Ô∏è Este modelo no tiene atributo 'feature_importances_'")
    
    return best_model, scaler

def validacion_inferencia_testfinal(X: pd.DataFrame, scaler, best_model, df_validacion: pd.DataFrame) -> Optional[np.ndarray]:

    """
    Realiza la validaci√≥n del modelo final usando un conjunto de validaci√≥n separado,
    escalando las variables, haciendo predicciones y mostrando m√©tricas y curva ROC.

    Par√°metros:
    - X (pd.DataFrame): DataFrame con las columnas predictoras utilizadas para entrenamiento.
    - scaler (StandardScaler): objeto scaler ajustado para escalar las variables predictoras.
    - best_model: modelo entrenado (estimador sklearn) a usar para inferencia.
    - df_validacion (pd.DataFrame): conjunto de validaci√≥n con las mismas columnas y variable 'Abandono'.

    Retorna:
    - y_val_prob (np.ndarray): probabilidades de la clase positiva para el conjunto de validaci√≥n.
      Retorna None si ocurre alg√∫n error en el proceso.
    """

       
    try:
        X_val = df_validacion[X.columns]
    except Exception as e:
        print("Error al crear X_val:", e)
        return None

    try:
        y_val = df_validacion['Abandono']
    except Exception as e:
        print("Error al crear y_val:", e)
        return None

  
    try:
        X_val_scaled = scaler.transform(X_val)
    except Exception as e:
        print("Error al escalar:", e)
        return None

   
    try:
        y_val_pred = best_model.predict(X_val_scaled)
        y_val_prob = best_model.predict_proba(X_val_scaled)[:, 1]
     
    except Exception as e:
        print("Error al predecir:", e)
        return None

  
    try:
        print("Accuracy:", accuracy_score(y_val, y_val_pred))
        print("Recall:", recall_score(y_val, y_val_pred))
        print("F1 Score:", f1_score(y_val, y_val_pred))
        print("Matriz de Confusi√≥n:\n", confusion_matrix(y_val, y_val_pred))

        fpr_val, tpr_val, _ = roc_curve(y_val, y_val_prob)
        roc_auc_val = auc(fpr_val, tpr_val)
        print("AUC (Inferencia Test):", round(roc_auc_val, 3))

        plt.plot(fpr_val, tpr_val, label=f'ROC (AUC = {roc_auc_val:.2f})')
        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlabel("FPR")
        plt.ylabel("TPR")
        plt.title("Curva ROC - Inferencia Test final")
        plt.legend()
        plt.show()
    except Exception as e:
        print("Error en m√©tricas o plot:", e)
        return None

    return y_val_prob


def clasificar_riesgo(df_validation: pd.DataFrame, y_val_prob: np.ndarray) -> pd.DataFrame:
    """
    A√±ade a un DataFrame de validaci√≥n la probabilidad de abandono y clasifica en niveles de riesgo.

    Par√°metros:
    - df_validation (pd.DataFrame): DataFrame con datos de validaci√≥n.
    - y_val_prob (np.ndarray): probabilidades predichas de abandono para cada fila en df_validation.

    Retorna:
    - df_validation (pd.DataFrame): DataFrame original enriquecido con columnas:
        - 'Prob_Abandono': probabilidad de abandono.
        - 'Nivel_Riesgo': categorizaci√≥n en niveles de riesgo ('Muy Bajo', 'Bajo', etc.).
    """

    # A√±adir columna de probabilidad de abandono
    df_validation["Prob_Abandono"] = y_val_prob

    # Crear niveles de riesgo
    df_validation["Nivel_Riesgo"] = pd.cut(df_validation["Prob_Abandono"], bins=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0],
        labels=["Muy Bajo", "Bajo", "Medio", "Alto", "Muy Alto"],  include_lowest=True)
    return df_validation